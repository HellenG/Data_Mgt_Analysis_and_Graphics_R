---
title: "Session Ten - Case Studies"
author: "By Hellen Gakuruh"
date: "July 22, 2016"
output: notebook_document
---

```{r "globalOptions", echo=FALSE}
library(knitr)
opts_chunk$set(
  collapse =  TRUE,
  dev = "png",
  warning = FALSE,
  message = FALSE,
  fig.path = "figures/"
)
```

Question: 
What has been covered, what has not been covered
  * Importing web data into R
  * Reading web data (html)
What have I read than needs synthesizing 
  * css selectors
  * Basics of Perl
  * Almost intermediate level regex
What is still pending in terms of reading
  * How to write efficient expressions
  * Perl's Regular Expressions (what distiguishes it from other regex programs)
  * R's regular expression --> Engine, types, pro and cons of each
  * For functions: How to minimize match and 

## Introduction

This session (ten) is more of a dynamic session as it will feature cases studies covering some of all introductory sessions in level one. I will propose the first case study but subsequent case studies will emanate from you. 

In all, this is meant to be an exciting indepth review of basic R.

## Session Goal
  
The main goal of this session is to apply lessons learnt in level one through a series of case studies. This is our first case study which aims to strengthen data exportation and processing skills with particular interest in web data. 

## Task{task}

Using pure base R (no packages), extract 800m and marathon data on recently held (summer) Olympics games and prepare it for data analysis (have data sets/frames ready).  

## What we shall cover

In addition to reviewing what we have covered in session one, we shall also learn how to:

* Extract  web data
    + Using base R "readLines()"
* Read and understand web data. This will include Hyper Text Markup Language (HTML) and Document Object (DO)
    + Why and what is HTML (What you see on web page is not what you import)
    + DO (core/loaded document) and DOM (api)
    + HTML DO composed of: declaration, elements and comments. Element composed of tags (opening and closing), attributes and content/text. Some elements (script) allow specification of actions through other languages like JS (for dynamic webpages). Some comments give conditions to perform certain task 
* Identify CSS selectors for traversing and extracting data
    + Basic selectors
        - Type
        - Universal
        - ID
        - Class
        - Other attributes
        - Pseudo-class
    + Grouping "," (if one is invalid, entire group is invalid)
    + Combinators (space, >, +, ~)
    + Pseudo-elements
* Craft basic regular expressions for data processing
    + What are regular expressions (and intro R regex functions)
    + Crafting regex:
        - Basic Matching (literals)
        - Characters classes, 
        - Alternatives and 
        - Position markers "^" and "$"
        - Quantifiers
    + Concept of backreferencing (parentheses)
    + Regular expression engines/machines
        - General concept (automata)
        - States
        - Concept of backtracking (differentiate with backreferencing)
    + How is it implemented in R
        - Extended Regular Expressions (default), PCRE 
        - Implementing PCRE
            + Small intro to Perl (just for regex use/understanding)
            

## Prerequisite

To appreciate this session, you must have gone through all the sessions in level one.


## Case Study One:- Importing online data, its all about Olympics

Our first case study is all about extracting online data and making it avaliable for analysis. Basic reason for having this as our first case study is because the web is full of (unutilised) data and most often you will find it necessary to use some of these data. To make this interesting, lets look at recently completed Olympics games; we have 2016 score and medals, but not it's trend. For this reason we want to look back at some events of interest and see how they have performed over time. 

As we venture into this case study, as much as our focus is gaining skills for online data importation or extraction, we should also brush-up on;

* creating data objects (data frame)
* converting data into a date-time object
* working with colors and plotting
* 
* 

Our olympics events of interest are 800m and marathon for both male and female athlets. We will extract data from wikipedia "https://en.wikipedia.org/wiki/800_meteres" and "https://en.wikipedia.org/wiki/Marathon_at_the_Olympics". What we need from these pages are tables giving medal standing for each event as of 2016.

The simplest part of web data extraction is actual importation of web data as package "xml2" can easily read the entire web page. However, to extract relevant sections of the web page will require use of another package like "rvest" and knowledge on reading web pages. Let us read in our data and see what we mean by "knowledge on web data".

### Importing online data

Since "Rvest" depends on "xml2", we can install "Rvest" package and it will come along with "xml2". 

```{r "installing_and_loading"}
if(!"rvest" %in% installed.packages()){ # Check if "rvest" is installed, if it is not installed, 
  install.packages("rvest")             # install it (requires web access)
}
# Load required package
library(rvest)

# Selectr Package
install.packages("selectr")
library(selectr)
# XML package
library(XML)
search()
```

When "rvest" is loading, you will see a message "Loading required package: xml2" which means xml2 package is installed and loaded with rvest hence we can call functions in xml2.  

There are two functions in "xml2" package for read in online data, these are "read_xml" and "read_html". XML and HTML are two markup languages used in web development. XML stands for "extensible markup language" while HTML stands for "hypertext markup language". Markup is information and/or instruction added to web content mostly for structure and display purposes. This markup comes in the form of [tags](#tags) where XML tags are extensible but undefined while HTML tags are defined. There is a third markup language that combines the advantage of both markup languages, this is XHTML which stands for "extensible hypertext markup language".  

Of the three markup languages, HTML is the standard languge used in web development, for this reason we will discuss markup as related to HTML and therefore we will import our data using "read_html()". However, since HTML is known to flaunt set rules, xml2 normalizes (improves validity) html by transforming it to xml. 

```{r "importingData", cache=TRUE}
olympics800m <- read_html(x = "https://en.wikipedia.org/wiki/800_metres")
olympicsMarathon <- read_html(x = "https://en.wikipedia.org/wiki/Marathons_at_the_Olympics")
```

Let us inspect our data.

```{r "inspectingData"}
olympics800m
olympicsMarathon
```

```{r, eval=FALSE}
library(rvest)
olympic800mTabs <- html_nodes(olympics800m, css = "table.wikitable.plainrowheaders")
```

We now have both web pages imported into R as lists with two elements; **xml node** and **xml document**. To understand how to extract relevant data, we need to have a basic understanding of HTML. Note, output generated are XML rather than HTML due to normalization (meaning xml2, has tried to correct HTML errors whenever they are found).

In subsequent section, we discuss how to read a HTML documents by grasping what constitutes HTML and then proceed to learn how to extract required data using CSS (cascading styling sheet) selectors.


#### Understanding HTML document

Synopis/summary/bigger picture

##### Basic HTML

When we extracted data from "wikipedia" (it can be any web source), this data is refered to as a **document objects**. Document objects are tree structures with the document object as the root and it's components as branches and leaves. This basically means a document object is a hierachial document with interelated components. <dfn id="markup>Document object are composed of markup and content where markup are information and instructions on how HTML content should be structured and displayed on a web page.</dfn> 

Everything within a document object is an object (which are basically markup and content) with direct or indirect relationship with the root object. In HTML, root document is simply "html" and everything within the document has a relationship with this root. This relationship is often referenced in terms of "kinship" or some sort of family analogy. The root document, in this case "html", is called "parent" which would have some direct children each of which is called it's `child`. These children refer to each other as `siblings` and they could have their own children which thus become `descendants` (more specifically grand children) of their parent or root document. Descendants can themselves have siblings and children leading to a chain of descendant. This family analogy is important to know as it maps where each object is and therefore one is able to extract needed data.

Before we see how an HTML document object looks like and how it can be shown as a tree structure, let's get a firm grasp of basic HTML. Basic HTML is composed of `declaration`, `elements` and `comments`. Declaration is an opening statement indicating html version used, this declaration is referred to as "document type declaration" (DTD) and are incased in `<! >` e.g `<!DOCTYPE html>` for HTML5. HTML comments are similar to comments in R as they provide guiding information, in HTML, they begin with `<!--` and end in `-->` for example "<!-- I am a HTML comment -->".   

<dfn id="element">In it's simplest form an **element** is composed of an **opening tag** only, but most are composed of **attributes**, **content** and **closing tags**.</dfn>

<dfn id="tags">**Tags** are markup or information added to web content. Strict or well formed HTML have *opening and closing tag*, although it is not uncommon to find source documents being parsed with only opening tags (this is because browsers are programmed to correct these errors). Since document objects read into R are parsed (syntatically correct code) and evaluated, they would have elements comprised of opening and closing tags with exception of [empty elements](#emptyElements). Both opening and closing tags start with a left angle bracket or less than sign and end with and right angle bracket or a greater than sign, i.e. `<tagname>`. Closing tags are distiguised from opening tags with a backslash, `/` i.e. `</tagname>`. Note, tags can embbed other tags which indicate a relatioship between the tags.

<dfn id="attributes">**Attributes** are additional information about an element, they are added to opening tags. This additional information could be an element identifier mostly used for styling or display purposes, or a description of content type for example a url link or an audio content. Attribute usualy come in "name=value" pair, for example "<html lang="en">"; here "html is an opening tag and "lang" is an attribute set to value "en" meaning english.

Both tags and attributes are the markup component of an element, they are not visible on a web page although they are used to change it appearance or make them dynamic/interactive. <dfn id="content">Content is the text or visible part of a web page; this what you see on web page. 

<dfn id="emptyElements">There are elements that have no content or closing tags, these are referred to as **empty elements**. Examples include line breaks which have a <br> tag, <link atttributes> tag, <meta> tag and so on. Well formed or strict HTML (XHTML) would close these tags with a backslash after tag name for example <br/>, <link/>.

Browsers are designed to overlook a lot of errors, for example, one could write a HTML source document without closing tags, and still be loaded. But when we download a HTML document (document object), we expect all opening tags to have ending tags with exception of empty element which will have backslash at the end of tag.

Here are examples of elements comprising of opening tags, attributes, content and closing tags. Note, in HTML comments begin with `/*` and end with `*/`.

```
Opening tags
=============
<h1>      /*This is a level one header*/
<p>       /*This indicates content is a paragraph*/
<table>   /*This begins a table*/
<a>       /*This is used to add links both internal (from the document) and external urls*/

Closing tags
============
</h1>     /*This closes a level one header*/
</p>      /*This marks end of a paragraph*/
</table>  /*This ends a table section*/
</a>      /*This ends a given link*/

Attributes added to opening tags
================================
<h1 class="center">                /*Attribute "class" is used by multiple  html elements to provide uniform styling or identification, in this case all elements with class center can be center aligned*/
<p dfn="html">                    /*Attribute "dfn" is used to mark first instance of a concept definition*/
<table id="firstTable">           /*Attribute "id" is a unique html object identifier, here it maps location of first table*/
<a href="https://myWebPage.org"> /*Attribute "href" specifies an external link*/

Complete element (opening tag, attribute, content and closing tag)
==================================================================
<h1 class="center">Welcome to my web page</h1>
<p dfn="myWebPage">My web page is a blog on matters R</p>
<table id="firstTable">...</table>  /*The "..." indicates nested tags for table headers and data. Each nested tag is an element*/
<a href="https://myWebPage.org">Link to my web page</a>
```

With that we have a basic understanding of how web pages are written. Let's look at a sample web page, this web page was created to provide update of 2016 olympics events. But before that, some few pointers on how to read HTML:

* First line ofcode is usually a document declaration, it resembles an element as it has angle brackets `<!DOCTYPE html>`; but it is not an element hence it will not be on the document tree. 
* Nested tags (those between opening and closing tags of another tag) are usually indented and on another line. Indentation indicates nested elements are either children or descendants of enclosing element. For example, the following HTML code will output an ordered list with three items. In this case <ol> is the "parent" tag and "li" are its children, each "li" is a sibling to the other  "li's". This relationship can be further referenced in term of first and last child to "ol".  

```
<ol>
  <li>Item one</li>
  <li>Item two</li>
  <li>Item three</li>
</ol>
```

* Elements on the same line are siblings   
* Sometimes on inspecting a document object, new line and indentation are not observed, when this is the case, check for opening and closing of a tag, any element within those two tags would be it's children and descendants. 
* <head> tag is meant to give information about the web document, this tag along side its nested tags are not visible on a web page, visible section of a web page begins from <body> tag
* Before HTML5 came along, it was quite common to find a lot of web documents separating different sections with <div> tag, this tag would embed other div tags. This divisions were mostly used for layout purposes. Newer web pages using HTML5 would use self describing tags for different section of a web page like <section> tag for a section, <nav> tag for a navigation panel, and <aside> tag for a side section. 

Click on our [sample web page](myOlympicsWatchTab2.html) to see how it looks like before reading it's code.

Here is our HTML code: 

```
<!DOCTYPE HTML> 
<html lang = "en-UK"> <!-- Root of this document, all other tags are direct children or descendants -->
  <head>
    <title>My Olympics 2016 Web Update Page</title>
    <link rel="stylesheet" type="text/css" href="myOlympicsWatchTab2.css">
	<meta name="keywords" content="Olympics 2016, Olympics update">
    <meta name="author" content="Hellen Gakuruh">
  </head>
    
<!-- Start of visible sections -->
  <body>
	
	<div id="body" class="center">
<!--A section for header text-->
      <div class="center" id="header">
        <h2 class="centerText">Welcome to my Web Page</h2>
        <p  class="centerText">This page will give an update of my favourite 2016 Olympics events</p>
      </div>

<!--A table to be populated with 2016 Olympics events updates-->
      <div id="table">
        <table class="center">
	      <caption>Update Table</caption>
          <thead>
		    <tr>
              <th>EVENT</th>
		      <th>GENDER</th>
              <th style="background-color:#FFD700">Gold</th>
              <th style="background-color:#CCCCCC">Silver</th>
			  <th style="background-color:#CC9966">Bronze</th>
            </tr>
		  </thead>
          <tbody class="centerText">
            <tr>
              <td rowspan="2">Marathon</td>
              <td>M</td>
		      <td>Eliud Kipchoge (K)</td>
              <td>Feyisa Lelisa</td>
			  <td>Galen Rupp</td>
            </tr>
		    <tr>
		      <td>F</td>
		      <td>Jemima Sumgong (K)</td>
		      <td>Eunice Kirwa</td>
			  <td>Mare Dibaba</td>
		    </tr>
            <tr>
              <td rowspan="2">800m</td>
		      <td>M</td>
              <td>David Rudisha (K)</td>
              <td>Taoufik Makhloufi</td>
			  <td>Clayton Murphy</td>
            </tr>
		    <tr>
		      <td>F</td>
		      <td>Caster Semenya</td>
		      <td>Francine Niyonsaba</td>
			  <td>Margaret Wambui (K)</td>
		    </tr>
          </tbody>
        </table>
    </div>
	<div id="image">
	  <img src="c://Users/user/Documents/Data Mania Inc/Data_Mgt_Analysis_and_Graphics_R/Class_Notes/Level One/figures/olympicsRings.png" alt="2016 Rio Olympics flag"/>
	  <div class="centerText" id="source"><a href="https://www.olympic.org/news/rio-2016">Rio 2016 Olympics Update</a></div>
	</div>
    </body>	
  </html>
```

TODO
=====
* Reduce row, make structure easy for tree construction
* Clearly define all relatioships (to be folowed up in the css selector section)

From above document object, we can see root element is `html` which has two children `head` and `body`, therefore head and body are siblings. "head" has four children, `title`, `link`, and two `meta` elements. Body has one child, also called an only child. This child has three `div` (division) children. The first "div" child has two children header `h2` and a paragraph `p`. Second child has one child `table` but table has three children and several descendants. Third child had two children, an image `img` and a `div`. This basic website can be shown on the following document tree.    

```{r}
#![Sample of a HTML Document Tree]()
```

To extract any part of this web page we can make reference of it relation to root element or its sibling, with this in mind, in our next section we look at how to make these references when extracting relevant parts of a web page. 

#### Extracting data using CSS selectors

Suppose from our sample web page we want to extract gold medalist for both male and female events (marathon and 800m) which is the third column titled gold. We can extract this infomation by identify something that is common in this column but unique from the rest of the document tree, by inspecting our document object. 

To inspect a document object of any web page, `right click` and select `Inspect`; document object should be displayed on the right hand side of the web page. Now look at the menu bar and ensure you are viewing "Elements" and if so, click on `body` element to reviel (sp) the visible part of the web document followed by it only child "div". Next click on "div" element with "id=table" and then "table" element. Finally click on "tbody" element as it contains required data. From "tbody" we can see it has has four children, all table rows and what we need are are either third or second children of table row. Question now is how can we reference or pick these two types elements? Before we answer this, let us take stock of what we know:

* First off, we know what is common among these two type of elements yet unique to the rest of the other elements, this is the "tbody" element: it contains all data we want and it is the only type or the only "tbody" element in this document object.
* Second, we know both type of elements are table data which are descendants of tbody (children of tbody's children)
* Third, and the distiguishing feature of these two types of elements, they are either third or second children of "tr" (table rows) which are direct children of tbody. 

To this extent we want a way to "select third table data (td) if gender is male and second table data if gender is female". This is basically a `conditional data extraction` which unfortunately is not possible when extracting online data; we can not say "if this then that". We therefore need to figure out some **pattern** that will match this condition. One possiblility is to look at it from an even and odd point of view, that is, for each odd table row (odd tr) in element "tbody", select the third child (3rd td) and second (2nd td) if even. Therefore we can create a pattern that begins from tbody and from it's odd children, it selects it's third grand children and for it's even children it selects it's second grand children. Using this logic, we can form a pattern to extract our required data.

```{r "readingSampleWEbPage"}
# Read in web data
sampleWebData <- read_html("myOlympicsWatchTab2.html")
sampleWebData

# Pattern search relevant data
maleMedalist   <- html_nodes(sampleWebData, "tbody tr:nth-of-type(odd)  td:nth-of-type(3)")
femaleMedalist <- html_nodes(sampleWebData, "tbody tr:nth-of-type(even) td:nth-of-type(2)")

# Gold medalist for both marathon and 800m as well as gender
c(html_text(maleMedalist), html_text(femaleMedalist))
```

Given our preceeding discussion, pattern used in the code above that is "tbody tr:nth-of-type(odd) td:nth-of-type(3)" should intuitively make some sense but to fully make sense of it, we need to learn pattern search using "CSS selectors". which used element (tag) names, relationship among element, position of an element and TOINCLUDE(aspects of pseudo-class/elements).

**CSS Selectors**

* Simple selectors
    + Type
    + Id
    + Class
    + Attributes
    + Pseudo-class Selectors
* Combinators
    + Space
    + ">"
    + "+"
    + "~"

#### Pseudo Class selectors

For data extraction main selectors are refered to as "structural pseudo-classes" and match elements based on their position on a document tree and their relation to other elements.


table:first-child 
This will match all tables that are a first child of an element. They must be the first element in their parent element.

table:nth-first-of-type
This will match all first tables in an element irrespective of their position in the element. This means that they could be second third or more position in a parent element but they are the first of their kind (table)


For programing
In both these two situations ("first-child" and "first-of-type"), elements are children of another element, they differ in matching. That is, given a parent element, first-child will match only if the first element is simple selector given, in the latter, it will match first type dispite it's position in parent element.

### Olympics 800m




```{r "800mTables"}
# Extract all table nodes
olympics800mTables <- html_nodes(olympics800m, "table.wikitable.plainrowheaders")
olympics800mTables
html_nodes(olympics800m, xpath = css_to_xpath("table.wikitable.plainrowheaders")) # Definately an rvest issue, but what
```

#### Male Events

* introduce magritter's pipe "%>%"

```{r "male800m", eval=FALSE}
# Column head for Olympics 800m male's table 
male800mColHead <- tables800m[1] %>%         # Extract first table from the list of the 4 Olympics tables
  html_nodes("th") %>%                       # Get table headers
  html_text()                                # Extract content without markup (What is visible on web page minus accompaning image)
library(rvest)
# Table data
male800mTabDat <- tables800m[1] %>%
  html_nodes("tr") %>%                       # Extract all table rows
  "["(-1)                      
```


#### Female Events


```{r "female800m", eval=FALSE}
library(rvest)
fem800mRows <- tables800m[2] %>%
  html_nodes("tr")
```


### Olympics Marathon

#### Male Events

#### Female Events


## References

### Base R Manual


### Packages Manuals and Vignettes

### Online web sites

## Exercise

For this session, try and come up with other case studies we can venture into, something that can have a greater interest and covering a number of areas discussed in level one. You can also try and do more web scraping as long as you observe web scraping ethics, for example copy right material or privacy information. 

Post Data Analysis Training Session Notes

Add a follow-up case study for scrapping twitter, facebook or LinkIn --> Authetication packages 
